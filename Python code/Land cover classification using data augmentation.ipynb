{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZloiIcGJpvu"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9uxDpvHJx-x"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfL6Nc96J2We"
      },
      "source": [
        "# Making multiple image tiles from single tile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE8IAD6TJ9R-"
      },
      "outputs": [],
      "source": [
        "!pip install geotile==0.2.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QNPn6QPKD_U"
      },
      "outputs": [],
      "source": [
        "from geotile import GeoTile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIKzQTYzKJUt"
      },
      "source": [
        "Connect Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBAFFZHzKMGb",
        "outputId": "c35ce7b4-28dd-4f46-e1db-451a56e0aca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLGShBnMMkuT"
      },
      "source": [
        "Creating tiles in several folders at once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDze99zzL9aJ"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW-38MFwo7Da"
      },
      "source": [
        "Five tiles are kept in five folders and five mask files are kept in five folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvwVfVFKQNyI"
      },
      "outputs": [],
      "source": [
        "folder_paths = [\n",
        "    '/content/gdrive/MyDrive/Colab Notebooks/pc/Tiles/One',          #Respective folder(s) in the drive\n",
        "    '/content/gdrive/MyDrive/Colab Notebooks/pc/Tiles/Two',\n",
        "    '/content/gdrive/MyDrive/Colab Notebooks/pc/Tiles/Three',\n",
        "    '/content/gdrive/MyDrive/Colab Notebooks/pc/Tiles/Four',\n",
        "    '/content/gdrive/MyDrive/Colab Notebooks/pc/Tiles/Five',\n",
        "    '/content/gdrive/MyDrive/Colab Notebooks/pc/Masks/One',\n",
        "    '/content/gdrive/MyDrive/Colab Notebooks/pc/Masks/Three',\n",
        "    '/content/gdrive/MyDrive/Colab Notebooks/pc/Masks/Two',\n",
        "    '/content/gdrive/MyDrive/Colab Notebooks/pc/Masks/Four',\n",
        "    '/content/gdrive/MyDrive/Colab Notebooks/pc/Masks/Five'\n",
        "    # Add more folder paths as needed\n",
        "]\n",
        "# Iterate over each folder path and generate the tiles\n",
        "for folder_path in folder_paths:\n",
        "    os.chdir(folder_path)\n",
        "    image_files = os.listdir(folder_path)\n",
        "    # Create the output folder corresponding to the input folder\n",
        "    output_folder = os.path.join(folder_path, 'output')\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for image_file in image_files:\n",
        "        if image_file.endswith('.tif'):  # Modify the extension if needed\n",
        "            gt = GeoTile(image_file)\n",
        "            gt.generate_tiles(output_folder)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mjtEBiTL3WI"
      },
      "source": [
        "Tiles from folder number one, two, four, and five are used for training and therefore are stored those in a sigle folder named 'train'. Tiles from the folder number three are used for testing and therefore are kept in the folder named 'test'. Both in train and test folders, there are two folders. One (images)is for storing the images and another (masks) is for storing the masks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQcKidlyhMj4"
      },
      "source": [
        "Checking the information of the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnLxJpR2fnsZ"
      },
      "outputs": [],
      "source": [
        "os.chdir(r\"/content/gdrive/MyDrive/Colab Notebooks/Data_Augmentation/train/images\")         #Respective folder(s) in the drive\n",
        "gt = GeoTile('75.tif')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAXTgkXfgQD5",
        "outputId": "06b302d9-3884-40d9-f771-246440636b2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gt.height"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haTNXmTngXEq",
        "outputId": "0c587a1e-6a3b-4656-b637-10902e06a080"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gt.width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87OUZjjahIzi",
        "outputId": "0749c1cb-950c-4eef-a6fd-b70aaa438b8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'driver': 'GTiff',\n",
              " 'dtype': 'uint8',\n",
              " 'nodata': 0.0,\n",
              " 'width': 256,\n",
              " 'height': 256,\n",
              " 'count': 3,\n",
              " 'crs': CRS.from_epsg(32611),\n",
              " 'transform': Affine(0.4994727339500307, 0.0, 464111.1503432652,\n",
              "        0.0, -0.4993928845171347, 5919139.720065584)}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gt.meta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2RVcZ6TIGtO"
      },
      "source": [
        "#Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxZQ3U9wIaeo"
      },
      "source": [
        "Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "491CAlgDIZtW"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from albumentations import CenterCrop, RandomRotate90, GridDistortion, HorizontalFlip, VerticalFlip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xa1B6CzJcj_"
      },
      "source": [
        "Function for loading input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiRdrV1SJYKW"
      },
      "outputs": [],
      "source": [
        "def load_data(path):                                                      #Respective folder(s) in the drive\n",
        "    images = sorted(glob(os.path.join(path, \"images/*\")))\n",
        "    masks = sorted(glob(os.path.join(path, \"masks/*\")))\n",
        "    return images, masks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waaj5J7FJjGn"
      },
      "source": [
        "Function for creating output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7eVcoddJr-V"
      },
      "outputs": [],
      "source": [
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HT7oPnBVJ0we"
      },
      "outputs": [],
      "source": [
        "import tifffile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLzUXM6SIMNl"
      },
      "source": [
        "Data augmentation for the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arLBCxqEIRhU",
        "outputId": "a5f133ac-cb3e-4f06-ef00-caf0cbca3406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Images: 100 - Original Masks: 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 39/100 [00:18<00:27,  2.21it/s]Exception ignored in: <function GeoTile.__del__ at 0x7fc7a54b0940>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/geotile/GeoTile.py\", line 66, in __del__\n",
            "    self.ds.close()\n",
            "AttributeError: 'GeoTile' object has no attribute 'ds'\n",
            "100%|██████████| 100/100 [00:48<00:00,  2.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Augmented Images: 600 - Augmented Masks: 600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import tifffile\n",
        "\n",
        "def augment_data(images, masks, save_path, augment=True):\n",
        "    H = 256\n",
        "    W = 256\n",
        "\n",
        "    for x, y in tqdm(zip(images, masks), total=len(images)):\n",
        "        name = x.split(\"/\")[-1].split(\".\")\n",
        "        \"\"\" Extracting the name and extension of the image and the mask. \"\"\"\n",
        "        image_name = name[0]\n",
        "        image_extn = name[1]\n",
        "\n",
        "        name = y.split(\"/\")[-1].split(\".\")\n",
        "        mask_name = name[0]\n",
        "        mask_extn = name[1]\n",
        "\n",
        "        \"\"\" Reading image and mask. \"\"\"\n",
        "        x = tifffile.imread(x)\n",
        "        y = tifffile.imread(y)\n",
        "\n",
        "        \"\"\" Augmentation \"\"\"\n",
        "        if augment == True:\n",
        "            aug = CenterCrop(H, W, p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x1 = augmented[\"image\"]\n",
        "            y1 = augmented[\"mask\"]\n",
        "\n",
        "            aug = RandomRotate90(p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x2 = augmented['image']\n",
        "            y2 = augmented['mask']\n",
        "\n",
        "            aug = GridDistortion(p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x3 = augmented['image']\n",
        "            y3 = augmented['mask']\n",
        "\n",
        "            aug = HorizontalFlip(p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x4 = augmented['image']\n",
        "            y4 = augmented['mask']\n",
        "\n",
        "            aug = VerticalFlip(p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x5 = augmented['image']\n",
        "            y5 = augmented['mask']\n",
        "\n",
        "            save_images = [x, x1, x2, x3, x4, x5]\n",
        "            save_masks =  [y, y1, y2, y3, y4, y5]\n",
        "\n",
        "        else:\n",
        "            save_images = [x]\n",
        "            save_masks = [y]\n",
        "\n",
        "        \"\"\" Saving the image and mask. \"\"\"\n",
        "        idx = 0\n",
        "        for i, m in zip(save_images, save_masks):\n",
        "            i = cv2.resize(i, (W, H))\n",
        "            m = cv2.resize(m, (W, H))\n",
        "\n",
        "            if len(images) == 1:\n",
        "                tmp_img_name = f\"{image_name}_i.{image_extn}\"\n",
        "                tmp_mask_name = f\"{mask_name}_l.{mask_extn}\"\n",
        "            else:\n",
        "                tmp_img_name = f\"{image_name}_{idx}_i.{image_extn}\"\n",
        "                tmp_mask_name = f\"{mask_name}_{idx}_l.{mask_extn}\"\n",
        "\n",
        "            image_path = os.path.join(save_path, \"images\", tmp_img_name)               \n",
        "            mask_path = os.path.join(save_path, \"masks\", tmp_mask_name)                \n",
        "\n",
        "            tifffile.imwrite(image_path, i)\n",
        "            tifffile.imwrite(mask_path, m)\n",
        "\n",
        "            idx += 1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Loading original images and masks. \"\"\"\n",
        "    path = \"/content/gdrive/MyDrive/Colab Notebooks/Data_Augmentation/train\"                      #Respective folder(s) in the drive\n",
        "    images, masks = load_data(path)\n",
        "    print(f\"Original Images: {len(images)} - Original Masks: {len(masks)}\")\n",
        "\n",
        "    \"\"\" Creating folders. \"\"\"\n",
        "    create_dir(\"/content/gdrive/MyDrive/Colab Notebooks/new_data_train/images\")\n",
        "    create_dir(\"/content/gdrive/MyDrive/Colab Notebooks/new_data_train/masks\")\n",
        "\n",
        "    \"\"\" Applying data augmentation. \"\"\"\n",
        "    augment_data(images, masks, \"/content/gdrive/MyDrive/Colab Notebooks/new_data_train\", augment=True)\n",
        "\n",
        "    \"\"\" Loading augmented images and masks. \"\"\"\n",
        "    images, masks = load_data(\"/content/gdrive/MyDrive/Colab Notebooks/new_data_train/\")\n",
        "    print(f\"Augmented Images: {len(images)} - Augmented Masks: {len(masks)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmU0Rvq6KzC6"
      },
      "source": [
        "Data augmentation for testing set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SttoLFyGKgp8",
        "outputId": "a1dc0a8b-5e79-4c2a-a842-5fc181979e1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Images: 25 - Original Masks: 25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:20<00:00,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Augmented Images: 150 - Augmented Masks: 150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import tifffile\n",
        "\n",
        "def augment_data(images, masks, save_path, augment=True):\n",
        "    H = 256\n",
        "    W = 256\n",
        "\n",
        "    for x, y in tqdm(zip(images, masks), total=len(images)):\n",
        "        name = x.split(\"/\")[-1].split(\".\")\n",
        "        \"\"\" Extracting the name and extension of the image and the mask. \"\"\"\n",
        "        image_name = name[0]\n",
        "        image_extn = name[1]\n",
        "\n",
        "        name = y.split(\"/\")[-1].split(\".\")\n",
        "        mask_name = name[0]\n",
        "        mask_extn = name[1]\n",
        "\n",
        "        \"\"\" Reading image and mask. \"\"\"\n",
        "        x = tifffile.imread(x)\n",
        "        y = tifffile.imread(y)\n",
        "\n",
        "        \"\"\" Augmentation \"\"\"\n",
        "        if augment == True:\n",
        "            aug = CenterCrop(H, W, p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x1 = augmented[\"image\"]\n",
        "            y1 = augmented[\"mask\"]\n",
        "\n",
        "            aug = RandomRotate90(p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x2 = augmented['image']\n",
        "            y2 = augmented['mask']\n",
        "\n",
        "            aug = GridDistortion(p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x3 = augmented['image']\n",
        "            y3 = augmented['mask']\n",
        "\n",
        "            aug = HorizontalFlip(p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x4 = augmented['image']\n",
        "            y4 = augmented['mask']\n",
        "\n",
        "            aug = VerticalFlip(p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x5 = augmented['image']\n",
        "            y5 = augmented['mask']\n",
        "\n",
        "            save_images = [x, x1, x2, x3, x4, x5]\n",
        "            save_masks =  [y, y1, y2, y3, y4, y5]\n",
        "\n",
        "        else:\n",
        "            save_images = [x]\n",
        "            save_masks = [y]\n",
        "\n",
        "        \"\"\" Saving the image and mask. \"\"\"\n",
        "        idx = 0\n",
        "        for i, m in zip(save_images, save_masks):\n",
        "            i = cv2.resize(i, (W, H))\n",
        "            m = cv2.resize(m, (W, H))\n",
        "\n",
        "            if len(images) == 1:\n",
        "                tmp_img_name = f\"{image_name}_i.{image_extn}\"\n",
        "                tmp_mask_name = f\"{mask_name}_l.{mask_extn}\"\n",
        "            else:\n",
        "                tmp_img_name = f\"{image_name}_{idx}_i.{image_extn}\"\n",
        "                tmp_mask_name = f\"{mask_name}_{idx}_l.{mask_extn}\"\n",
        "\n",
        "            image_path = os.path.join(save_path, \"images\", tmp_img_name)\n",
        "            mask_path = os.path.join(save_path, \"masks\", tmp_mask_name)\n",
        "\n",
        "            tifffile.imwrite(image_path, i)\n",
        "            tifffile.imwrite(mask_path, m)\n",
        "\n",
        "            idx += 1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Loading original images and masks. \"\"\"\n",
        "    path = \"/content/gdrive/MyDrive/Colab Notebooks/Data_Augmentation/test\"                      #Respective folder(s) in the drive\n",
        "    images, masks = load_data(path)\n",
        "    print(f\"Original Images: {len(images)} - Original Masks: {len(masks)}\")\n",
        "\n",
        "    \"\"\" Creating folders. \"\"\"\n",
        "    create_dir(\"/content/gdrive/MyDrive/Colab Notebooks/new_data_test/images\")\n",
        "    create_dir(\"/content/gdrive/MyDrive/Colab Notebooks/new_data_test/masks\")\n",
        "\n",
        "    \"\"\" Applying data augmentation. \"\"\"\n",
        "    augment_data(images, masks, \"/content/gdrive/MyDrive/Colab Notebooks/new_data_test\", augment=True)\n",
        "\n",
        "    \"\"\" Loading augmented images and masks. \"\"\"\n",
        "    images, masks = load_data(\"/content/gdrive/MyDrive/Colab Notebooks/new_data_test/\")\n",
        "    print(f\"Augmented Images: {len(images)} - Augmented Masks: {len(masks)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad45YQazYxKc"
      },
      "source": [
        "# Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpQ_OZyNY9EC"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Concatenate, Dropout\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyQLZm4UZqnV"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0AvMLq_fjKb"
      },
      "source": [
        "Set the working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9C_PfsEMfo07"
      },
      "outputs": [],
      "source": [
        "os.chdir(r'/content/gdrive/MyDrive/Colab Notebooks/Modeling')          #Respective folder(s) in the drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0dWDE-lnnc7"
      },
      "source": [
        "Now, all the images and masks (original and augmented) for training are stored in one folder named 'training', and all the images and masks (original and augmented) for testing are stored in another folder named 'testing'. These training and testing folders are kept inside the 'Modeling' folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u08UsuPdZtLF",
        "outputId": "6384d033-c1e1-4a68-cdec-5f7c6a893899"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "600 150\n"
          ]
        }
      ],
      "source": [
        "train_x = sorted(glob.glob('training/*_i.tif'))\n",
        "train_y = sorted(glob.glob('training/*_l.tif'))\n",
        "test_x = sorted(glob.glob('testing/*_i.tif'))\n",
        "test_y = sorted(glob.glob('testing/*_l.tif'))\n",
        "\n",
        "print(len(train_x), len(test_x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU8_yrTEaTTl"
      },
      "source": [
        "Converting training image to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYhuQsZZaXBU"
      },
      "outputs": [],
      "source": [
        "train_xx = np.zeros((600, 256, 256, 3))\n",
        "train_yy = np.zeros((600, 256, 256, 1))\n",
        "for i, (img, mask) in enumerate(zip(train_x, train_y)):\n",
        "  # if i == 1:\n",
        "  #   break\n",
        "\n",
        "  img = Image.open(img)\n",
        "  np_img = np.array(img)\n",
        "  train_xx[i] = np_img\n",
        "\n",
        "  mask = Image.open(mask)\n",
        "  np_mask = np.array(mask).reshape(256, 256, 1)\n",
        "  train_yy[i] = np_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUIEBAt1dD39"
      },
      "source": [
        "Converting testing image to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5u9xtLqjdHim"
      },
      "outputs": [],
      "source": [
        "test_xx = np.zeros((150, 256, 256, 3))\n",
        "test_yy = np.zeros((150, 256, 256, 1))\n",
        "for i, (img, mask) in enumerate(zip(test_x, test_y)):\n",
        "\n",
        "  img = Image.open(img)\n",
        "  np_img = np.array(img)\n",
        "  test_xx[i] = np_img\n",
        "\n",
        "  mask = Image.open(mask)\n",
        "  np_mask = np.array(mask).reshape(256, 256, 1)\n",
        "  test_yy[i] = np_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe-M-mMjdyVK"
      },
      "source": [
        "Let's plot a sample input RGB image and output image with classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RHmWuZcd2xO"
      },
      "outputs": [],
      "source": [
        "plt.imshow(train_xx[500, :, :, :].astype('uint8'))\n",
        "plt.show()\n",
        "plt.imshow(train_yy[500, :, :, 0].astype('uint8'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P_vS76CeTqh"
      },
      "source": [
        "# Save to numpy format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLPnIz-GeWW7",
        "outputId": "f9c48fdb-819d-4b63-8e62-af06eaff5d19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(600, 256, 256, 3)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_xx.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3eBuYJPha1x",
        "outputId": "b05e2a21-363a-4dab-fe81-39f5802b72cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(600, 256, 256, 1)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_yy.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGkc_AJWep-z"
      },
      "outputs": [],
      "source": [
        "np.save('train_xx.npy', train_xx)\n",
        "np.save('train_yy.npy', train_yy)\n",
        "np.save(\"test_xx.npy\", test_xx)\n",
        "np.save(\"test_yy.npy\", test_yy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4yYcOTSjGI-"
      },
      "source": [
        "# Data for land use land cover mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvdQUgEOjMTE"
      },
      "source": [
        "Input data are RGB satellite images. And output are images of land cover type. There are 6 land cover types as below,\n",
        "\n",
        "- Pixel value 1: Road\n",
        "- Pixel value 2: Building\n",
        "- Pixel value 3: Needle leaf\n",
        "- Pixel value 4: Broad leaf\n",
        "- Pixel value 5: Barren land\n",
        "- Pixel value 6: Unlabelled\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm5hpU1Zl66P"
      },
      "source": [
        "Data is already randomized and split in to training / test sets. So we can go ahead and use them as it is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d8VWPN5l8yA",
        "outputId": "17081ce9-e581-4cfd-fa12-484d1c8c0c35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape (600, 256, 256, 3)\n",
            "y_train shape (600, 256, 256, 1)\n",
            "y_test shape (150, 256, 256, 3)\n",
            "y_test shape (150, 256, 256, 1)\n"
          ]
        }
      ],
      "source": [
        "x_train = np.load('train_xx.npy').astype('float32')\n",
        "y_train= np.load('train_yy.npy').astype('float32')\n",
        "x_test = np.load('test_xx.npy').astype('float32')\n",
        "y_test = np.load('test_yy.npy').astype('float32')\n",
        "\n",
        "print(\"x_train shape\", x_train.shape)\n",
        "print(\"y_train shape\", y_train.shape)\n",
        "print(\"y_test shape\", x_test.shape)\n",
        "print(\"y_test shape\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rZB_5POmz5K"
      },
      "source": [
        "Let's plot a sample input RGB image and output image with land cover"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_np7foMvm3TO"
      },
      "outputs": [],
      "source": [
        "plt.imshow(x_test[100,:,:,:].astype('uint8'))\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(y_test[100,:,:,0].astype('uint8'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzN7zDgPnM1w"
      },
      "source": [
        "Since land cover data include classes, let's perform one-hot encoding first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhDKPOHznPfR",
        "outputId": "ea1d3505-0a2b-4e55-8420-01563850efaa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(600, 256, 256, 7)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_1hot = to_categorical(y_train)\n",
        "y_test_1hot = to_categorical(y_test)\n",
        "\n",
        "y_train_1hot.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDP5pbLqnm8X"
      },
      "source": [
        "# Model development (Unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwsSxIQRnn_P",
        "outputId": "969af464-bf69-4e72-8e13-4c1cb90a2f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 32  896         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 256, 256, 32  0           ['conv2d[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 32  9248        ['dropout[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 32  0           ['conv2d_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 32  9248        ['max_pooling2d[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 128, 128, 32  0           ['conv2d_2[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 32  9248        ['dropout_1[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)  0           ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 64, 64, 64)   18496       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 64, 64, 64)   0           ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 64)   36928       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)  0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 64)   36928       ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 32, 32, 64)   0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 64)   36928       ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 32, 32, 64)  36928       ['conv2d_7[0][0]']               \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 32, 32, 64)   0           ['conv2d_transpose[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 64)  36928       ['dropout_4[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64, 64, 128)  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                                                  'conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 64, 64, 64)  73792       ['concatenate[0][0]']            \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 64, 64, 64)   0           ['conv2d_transpose_2[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 128, 128, 64  36928      ['dropout_5[0][0]']              \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128, 128, 96  0           ['conv2d_transpose_3[0][0]',     \n",
            "                                )                                 'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2DTran  (None, 128, 128, 32  27680      ['concatenate_1[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 128, 128, 32  0           ['conv2d_transpose_4[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2DTran  (None, 256, 256, 32  9248       ['dropout_6[0][0]']              \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 256, 256, 64  0           ['conv2d_transpose_5[0][0]',     \n",
            "                                )                                 'conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_transpose_6 (Conv2DTran  (None, 256, 256, 32  18464      ['concatenate_2[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 256, 256, 32  0           ['conv2d_transpose_6[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_7 (Conv2DTran  (None, 256, 256, 32  9248       ['dropout_7[0][0]']              \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 256, 256, 32  1056        ['conv2d_transpose_7[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 256, 256, 32  1056        ['conv2d_8[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 256, 256, 7)  231         ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 409,479\n",
            "Trainable params: 409,479\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x_in = Input(shape=(256, 256, 3))\n",
        "\n",
        "'''Encoder'''\n",
        "x_temp = Conv2D(32, (3, 3), activation='relu', padding='same')(x_in)\n",
        "x_temp = Dropout(0.25)(x_temp)\n",
        "x_skip1 = Conv2D(32, (3, 3), activation='relu', padding='same')(x_temp)\n",
        "x_temp = MaxPooling2D((2,2))(x_skip1)\n",
        "x_temp = Conv2D(32, (3, 3), activation='relu', padding='same')(x_temp)\n",
        "x_temp = Dropout(0.25)(x_temp)\n",
        "x_skip2 = Conv2D(32, (3, 3), activation='relu', padding='same')(x_temp)\n",
        "x_temp = MaxPooling2D((2,2))(x_skip2)\n",
        "x_temp = Conv2D(64, (3, 3), activation='relu', padding='same')(x_temp)\n",
        "x_temp = Dropout(0.25)(x_temp)\n",
        "x_skip3 = Conv2D(64, (3, 3), activation='relu', padding='same')(x_temp)\n",
        "x_temp = MaxPooling2D((2,2))(x_skip3)\n",
        "x_temp = Conv2D(64, (3, 3), activation='relu', padding='same')(x_temp)\n",
        "x_temp = Dropout(0.5)(x_temp)\n",
        "x_temp = Conv2D(64, (3, 3), activation='relu', padding='same')(x_temp)\n",
        "\n",
        "'''Decoder'''\n",
        "x_temp = Conv2DTranspose(64, (3, 3), activation='relu',  padding='same')(x_temp)\n",
        "x_temp = Dropout(0.5)(x_temp)\n",
        "x_temp = Conv2DTranspose(64, (3, 3), strides=(2, 2), activation='relu',  padding='same')(x_temp)\n",
        "x_temp = Concatenate()([x_temp, x_skip3])\n",
        "x_temp = Conv2DTranspose(64, (3, 3), activation='relu',  padding='same')(x_temp)\n",
        "x_temp = Dropout(0.5)(x_temp)\n",
        "x_temp = Conv2DTranspose(64, (3, 3), strides=(2, 2), activation='relu',  padding='same')(x_temp)\n",
        "x_temp = Concatenate()([x_temp, x_skip2])\n",
        "x_temp = Conv2DTranspose(32, (3, 3), activation='relu',  padding='same')(x_temp)\n",
        "x_temp = Dropout(0.5)(x_temp)\n",
        "x_temp = Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu',  padding='same')(x_temp)\n",
        "x_temp = Concatenate()([x_temp, x_skip1])\n",
        "x_temp = Conv2DTranspose(32, (3, 3), activation='relu',  padding='same')(x_temp)\n",
        "x_temp = Dropout(0.5)(x_temp)\n",
        "x_temp = Conv2DTranspose(32, (3, 3), activation='relu',  padding='same')(x_temp)\n",
        "\n",
        "'''Use 1 by 1 Convolution to get desired output bands'''\n",
        "x_temp = Conv2D(32, (1, 1), activation='relu', padding='same')(x_temp)\n",
        "x_temp = Conv2D(32, (1, 1), activation='relu', padding='same')(x_temp)\n",
        "x_out = Conv2D(7, (1, 1), activation='softmax', padding='same')(x_temp)\n",
        "\n",
        "model = Model(inputs=x_in, outputs=x_out)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znjxbjCroNSR",
        "outputId": "ad9e1f6f-2704-4e5d-ee69-f8902fc65df2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "12/12 [==============================] - 13s 1s/step - loss: 0.5190 - accuracy: 0.8210 - val_loss: 1.5131 - val_accuracy: 0.5489\n",
            "Epoch 2/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.5682 - accuracy: 0.7918 - val_loss: 1.1316 - val_accuracy: 0.6292\n",
            "Epoch 3/80\n",
            "12/12 [==============================] - 12s 997ms/step - loss: 0.5166 - accuracy: 0.8203 - val_loss: 0.9474 - val_accuracy: 0.6904\n",
            "Epoch 4/80\n",
            "12/12 [==============================] - 12s 970ms/step - loss: 0.4905 - accuracy: 0.8280 - val_loss: 0.9058 - val_accuracy: 0.7168\n",
            "Epoch 5/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.4770 - accuracy: 0.8322 - val_loss: 0.7971 - val_accuracy: 0.7398\n",
            "Epoch 6/80\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.4663 - accuracy: 0.8349 - val_loss: 0.8585 - val_accuracy: 0.7234\n",
            "Epoch 7/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.4618 - accuracy: 0.8355 - val_loss: 0.8295 - val_accuracy: 0.7200\n",
            "Epoch 8/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.4561 - accuracy: 0.8371 - val_loss: 0.8939 - val_accuracy: 0.7045\n",
            "Epoch 9/80\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.4521 - accuracy: 0.8379 - val_loss: 0.8793 - val_accuracy: 0.7192\n",
            "Epoch 10/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.4526 - accuracy: 0.8387 - val_loss: 0.9788 - val_accuracy: 0.6838\n",
            "Epoch 11/80\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.4626 - accuracy: 0.8343 - val_loss: 0.9304 - val_accuracy: 0.7055\n",
            "Epoch 12/80\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.4583 - accuracy: 0.8365 - val_loss: 0.8120 - val_accuracy: 0.7333\n",
            "Epoch 13/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.4487 - accuracy: 0.8392 - val_loss: 0.8310 - val_accuracy: 0.7314\n",
            "Epoch 14/80\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.4399 - accuracy: 0.8417 - val_loss: 0.8082 - val_accuracy: 0.7374\n",
            "Epoch 15/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.4452 - accuracy: 0.8400 - val_loss: 0.8852 - val_accuracy: 0.6895\n",
            "Epoch 16/80\n",
            "12/12 [==============================] - 12s 992ms/step - loss: 0.4477 - accuracy: 0.8393 - val_loss: 1.0161 - val_accuracy: 0.6736\n",
            "Epoch 17/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.4374 - accuracy: 0.8429 - val_loss: 0.8608 - val_accuracy: 0.7226\n",
            "Epoch 18/80\n",
            "12/12 [==============================] - 12s 999ms/step - loss: 0.4273 - accuracy: 0.8457 - val_loss: 0.9596 - val_accuracy: 0.7054\n",
            "Epoch 19/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.4221 - accuracy: 0.8474 - val_loss: 0.8724 - val_accuracy: 0.7141\n",
            "Epoch 20/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.4189 - accuracy: 0.8485 - val_loss: 0.8930 - val_accuracy: 0.7007\n",
            "Epoch 21/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.4194 - accuracy: 0.8479 - val_loss: 0.8062 - val_accuracy: 0.7398\n",
            "Epoch 22/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.4216 - accuracy: 0.8480 - val_loss: 1.0436 - val_accuracy: 0.6698\n",
            "Epoch 23/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.4140 - accuracy: 0.8498 - val_loss: 0.9856 - val_accuracy: 0.6897\n",
            "Epoch 24/80\n",
            "12/12 [==============================] - 12s 991ms/step - loss: 0.4079 - accuracy: 0.8520 - val_loss: 0.9576 - val_accuracy: 0.6997\n",
            "Epoch 25/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.4009 - accuracy: 0.8542 - val_loss: 1.4092 - val_accuracy: 0.6460\n",
            "Epoch 26/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.4063 - accuracy: 0.8525 - val_loss: 0.8975 - val_accuracy: 0.7013\n",
            "Epoch 27/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.4038 - accuracy: 0.8531 - val_loss: 1.0078 - val_accuracy: 0.7015\n",
            "Epoch 28/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.4080 - accuracy: 0.8523 - val_loss: 1.0269 - val_accuracy: 0.6630\n",
            "Epoch 29/80\n",
            "12/12 [==============================] - 12s 987ms/step - loss: 0.4036 - accuracy: 0.8546 - val_loss: 1.0573 - val_accuracy: 0.6634\n",
            "Epoch 30/80\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.3924 - accuracy: 0.8571 - val_loss: 0.9633 - val_accuracy: 0.7137\n",
            "Epoch 31/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3878 - accuracy: 0.8582 - val_loss: 0.8803 - val_accuracy: 0.7137\n",
            "Epoch 32/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3859 - accuracy: 0.8584 - val_loss: 0.8655 - val_accuracy: 0.7351\n",
            "Epoch 33/80\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.3808 - accuracy: 0.8607 - val_loss: 1.2273 - val_accuracy: 0.6868\n",
            "Epoch 34/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3874 - accuracy: 0.8580 - val_loss: 0.9355 - val_accuracy: 0.6994\n",
            "Epoch 35/80\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.3786 - accuracy: 0.8605 - val_loss: 0.9253 - val_accuracy: 0.7226\n",
            "Epoch 36/80\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.3750 - accuracy: 0.8611 - val_loss: 0.9104 - val_accuracy: 0.7125\n",
            "Epoch 37/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3756 - accuracy: 0.8605 - val_loss: 0.9061 - val_accuracy: 0.7130\n",
            "Epoch 38/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3690 - accuracy: 0.8624 - val_loss: 1.0837 - val_accuracy: 0.6998\n",
            "Epoch 39/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3618 - accuracy: 0.8656 - val_loss: 1.0572 - val_accuracy: 0.6895\n",
            "Epoch 40/80\n",
            "12/12 [==============================] - 12s 996ms/step - loss: 0.3635 - accuracy: 0.8646 - val_loss: 0.9099 - val_accuracy: 0.7096\n",
            "Epoch 41/80\n",
            "12/12 [==============================] - 12s 997ms/step - loss: 0.4293 - accuracy: 0.8401 - val_loss: 0.9262 - val_accuracy: 0.6402\n",
            "Epoch 42/80\n",
            "12/12 [==============================] - 12s 996ms/step - loss: 0.3972 - accuracy: 0.8552 - val_loss: 0.8434 - val_accuracy: 0.7409\n",
            "Epoch 43/80\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.3733 - accuracy: 0.8615 - val_loss: 0.8876 - val_accuracy: 0.7311\n",
            "Epoch 44/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3627 - accuracy: 0.8654 - val_loss: 0.8961 - val_accuracy: 0.7360\n",
            "Epoch 45/80\n",
            "12/12 [==============================] - 12s 993ms/step - loss: 0.3678 - accuracy: 0.8633 - val_loss: 0.9124 - val_accuracy: 0.7271\n",
            "Epoch 46/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3530 - accuracy: 0.8693 - val_loss: 0.8800 - val_accuracy: 0.7152\n",
            "Epoch 47/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3474 - accuracy: 0.8709 - val_loss: 0.8515 - val_accuracy: 0.7420\n",
            "Epoch 48/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3546 - accuracy: 0.8676 - val_loss: 0.9006 - val_accuracy: 0.7312\n",
            "Epoch 49/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3514 - accuracy: 0.8706 - val_loss: 0.8717 - val_accuracy: 0.7294\n",
            "Epoch 50/80\n",
            "12/12 [==============================] - 13s 1s/step - loss: 0.3384 - accuracy: 0.8756 - val_loss: 0.8310 - val_accuracy: 0.7410\n",
            "Epoch 51/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3562 - accuracy: 0.8661 - val_loss: 0.8459 - val_accuracy: 0.7309\n",
            "Epoch 52/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3552 - accuracy: 0.8698 - val_loss: 0.8736 - val_accuracy: 0.7236\n",
            "Epoch 53/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3406 - accuracy: 0.8751 - val_loss: 0.8836 - val_accuracy: 0.7157\n",
            "Epoch 54/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3401 - accuracy: 0.8755 - val_loss: 1.0549 - val_accuracy: 0.6951\n",
            "Epoch 55/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3475 - accuracy: 0.8708 - val_loss: 0.8863 - val_accuracy: 0.7242\n",
            "Epoch 56/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3368 - accuracy: 0.8760 - val_loss: 0.8397 - val_accuracy: 0.7488\n",
            "Epoch 57/80\n",
            "12/12 [==============================] - 12s 990ms/step - loss: 0.3263 - accuracy: 0.8798 - val_loss: 0.9426 - val_accuracy: 0.7405\n",
            "Epoch 58/80\n",
            "12/12 [==============================] - 12s 985ms/step - loss: 0.3203 - accuracy: 0.8827 - val_loss: 0.8837 - val_accuracy: 0.7393\n",
            "Epoch 59/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3144 - accuracy: 0.8847 - val_loss: 0.9614 - val_accuracy: 0.7009\n",
            "Epoch 60/80\n",
            "12/12 [==============================] - 12s 999ms/step - loss: 0.3344 - accuracy: 0.8773 - val_loss: 0.9421 - val_accuracy: 0.7017\n",
            "Epoch 61/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3213 - accuracy: 0.8826 - val_loss: 0.9840 - val_accuracy: 0.6944\n",
            "Epoch 62/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3168 - accuracy: 0.8838 - val_loss: 0.8543 - val_accuracy: 0.7369\n",
            "Epoch 63/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3075 - accuracy: 0.8870 - val_loss: 0.9860 - val_accuracy: 0.7341\n",
            "Epoch 64/80\n",
            "12/12 [==============================] - 12s 998ms/step - loss: 0.3019 - accuracy: 0.8891 - val_loss: 0.9239 - val_accuracy: 0.7328\n",
            "Epoch 65/80\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.3056 - accuracy: 0.8878 - val_loss: 0.9084 - val_accuracy: 0.7355\n",
            "Epoch 66/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3135 - accuracy: 0.8842 - val_loss: 0.8939 - val_accuracy: 0.7471\n",
            "Epoch 67/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3084 - accuracy: 0.8868 - val_loss: 0.9204 - val_accuracy: 0.7449\n",
            "Epoch 68/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.3021 - accuracy: 0.8890 - val_loss: 0.9145 - val_accuracy: 0.7452\n",
            "Epoch 69/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.2952 - accuracy: 0.8914 - val_loss: 0.9903 - val_accuracy: 0.7232\n",
            "Epoch 70/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.2932 - accuracy: 0.8924 - val_loss: 0.9583 - val_accuracy: 0.7233\n",
            "Epoch 71/80\n",
            "12/12 [==============================] - 13s 1s/step - loss: 0.2929 - accuracy: 0.8921 - val_loss: 0.9314 - val_accuracy: 0.7303\n",
            "Epoch 72/80\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.2893 - accuracy: 0.8935 - val_loss: 0.9520 - val_accuracy: 0.7241\n",
            "Epoch 73/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.2872 - accuracy: 0.8941 - val_loss: 0.9711 - val_accuracy: 0.7267\n",
            "Epoch 74/80\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.2844 - accuracy: 0.8951 - val_loss: 1.0236 - val_accuracy: 0.7308\n",
            "Epoch 75/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.2936 - accuracy: 0.8918 - val_loss: 0.9106 - val_accuracy: 0.7333\n",
            "Epoch 76/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.2914 - accuracy: 0.8933 - val_loss: 0.9292 - val_accuracy: 0.7305\n",
            "Epoch 77/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.2849 - accuracy: 0.8948 - val_loss: 1.0047 - val_accuracy: 0.7244\n",
            "Epoch 78/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.6153 - accuracy: 0.7988 - val_loss: 1.2788 - val_accuracy: 0.4827\n",
            "Epoch 79/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.9877 - accuracy: 0.6680 - val_loss: 0.9226 - val_accuracy: 0.6900\n",
            "Epoch 80/80\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.8428 - accuracy: 0.6866 - val_loss: 0.8037 - val_accuracy: 0.7164\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train, y_train_1hot, validation_data=(x_test, y_test_1hot), epochs=10, batch_size=50, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVeS5H4H_P0n"
      },
      "source": [
        "Plot the loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgdD3LzKidO_"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "ax1.plot(history.history['accuracy'])\n",
        "ax1.plot(history.history['val_accuracy'])\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.set_title('Accuracy over epoch')\n",
        "ax1.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "ax2.plot(history.history['loss'])\n",
        "ax2.plot(history.history['val_loss'])\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.set_title('Loss over epoch')\n",
        "ax2.legend(['Train', 'Test'], loc=\"upper right\")\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig('/content/gdrive/MyDrive/Colab Notebooks/Modeling/figure.png')             #Respective folder(s) in the drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HYdKjJr_mw-"
      },
      "source": [
        "#Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMi8LBVo_oxi",
        "outputId": "4cff0dca-3d2a-42f1-d1f8-2d01d9630c4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 142ms/step\n",
            "(150, 256, 256)\n"
          ]
        }
      ],
      "source": [
        "'''Prediction over the test dataset'''\n",
        "pred_test = model.predict(x_test)\n",
        "\n",
        "pred_test = np.argmax(pred_test, axis=-1)\n",
        "print(pred_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-byz9TSw8I9"
      },
      "source": [
        "Save the predicted images in the directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InQue-GNt_CF",
        "outputId": "9d88ae8a-c4b2-4b18-9d03-182f25965f06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted images saved successfully.\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Create a directory to store the predicted images\n",
        "save_dir = '/content/gdrive/MyDrive/Colab Notebooks/predicted_images_withAugmentation'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Save each predicted image to the directory\n",
        "for i in range(pred_test.shape[0]):\n",
        "    image = pred_test[i, :, :]\n",
        "    image = np.uint8(image * 255)  # Convert to uint8\n",
        "    image = np.squeeze(image)  # Remove the single-channel dimension if present\n",
        "    image_path = os.path.join(save_dir, f'predicted_image_{i}.png')\n",
        "    Image.fromarray(image).save(image_path)\n",
        "\n",
        "print(\"Predicted images saved successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3LrpLcz_wbP"
      },
      "source": [
        "let's compare sample predicted and actual land cover image with input RGB image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3P82388_0WL"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(pred_test[48, :, :])\n",
        "plt.title('Predicted Mask (Augmented)')\n",
        "plt.show()\n",
        "#plt.savefig('/content/gdrive/MyDrive/Colab Notebooks/Modeling/figurePA.png')\n",
        "plt.imshow(y_test[48, :, :, 0])\n",
        "plt.title('Original Mask')\n",
        "plt.show()\n",
        "#plt.savefig('/content/gdrive/MyDrive/Colab Notebooks/Modeling/figureOM.png')\n",
        "plt.imshow(x_test[48,:,:,:].astype('uint8'))\n",
        "plt.title('Original Tile')\n",
        "plt.show()\n",
        "#plt.savefig('/content/gdrive/MyDrive/Colab Notebooks/Modeling/figureOT.png')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
